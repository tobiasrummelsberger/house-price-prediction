{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI Monthly Challenge - House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of data\n",
    "Defining the path and names of the input csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "PATH = 'C:/Users/TobiasRummelsberger/PycharmProjects/house-price-prediction/'\n",
    "#PATH = '/Users/tobias/PycharmProjects/house-price-prediction/'\n",
    "DATA_PATH = 'obj/data/'\n",
    "MODEL_PATH = 'obj/model'\n",
    "\n",
    "train_path = 'input_data/train.csv'\n",
    "test_path = 'input_data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains 43 categorical features and 37 numerical features. The train data set contains 1168 rows and the test data set contains 292 rows.\n",
      "The categorical features are ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'] and the numerical features are ['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from load_data import load_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(PATH + DATA_PATH + train_path)\n",
    "\n",
    "#X_test = pd.read_csv(PATH + DATA_PATH + test_path)\n",
    "#submission_index = X_test['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "Get an overview of the data and most important features by plotting a correlation matrix and a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exploratory_data_analysis.eda import plot_correlation_matrix, plot_scatter_matrix\n",
    "\n",
    "plot_correlation_matrix(X_train)\n",
    "#plot_scatter_matrix(X_train, columns=['SalePrice', 'LotArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacement of NAs\n",
    "NA values are replaced with either a 0 (in numerical columns) or 'None' (in categorical columns) or with the median of the column if feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_preprocessing import preprocess_alley, preprocess_LotFrontage, preprocess_MasVnrType, preprocess_BsmtQual, preprocess_BsmtCond, preprocess_BsmtExposure, preprocess_BsmtFinType1, preprocess_BsmtFinType2, preprocess_Electrical, preprocess_FireplaceQu, preprocess_GarageType, preprocess_GarageFinish, preprocess_GarageQual, preprocess_GarageCond, preprocess_PoolQC, preprocess_Fence, preprocess_MiscFeature, preprocess_MSZoning, preprocess_Utilities, preprocess_Exterior1st, preprocess_Exterior2nd, preprocess_KitchenQual, preprocess_Functional, preprocess_SaleType, preprocess_GarageYrBlt, preprocess_MasVnrArea\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test = preprocess_alley(X_train, X_test)\n",
    "X_train, X_test = preprocess_MSZoning(X_train, X_test)\n",
    "X_train, X_test = preprocess_LotFrontage(X_train, X_test)\n",
    "X_train, X_test = preprocess_MasVnrType(X_train, X_test)\n",
    "X_train, X_test = preprocess_BsmtQual(X_train, X_test)\n",
    "X_train, X_test = preprocess_BsmtCond(X_train, X_test)\n",
    "X_train, X_test = preprocess_BsmtExposure(X_train, X_test)\n",
    "X_train, X_test = preprocess_BsmtFinType1(X_train, X_test)\n",
    "X_train, X_test = preprocess_BsmtFinType2(X_train, X_test)\n",
    "X_train, X_test = preprocess_Electrical(X_train, X_test)\n",
    "X_train, X_test = preprocess_FireplaceQu(X_train, X_test)\n",
    "X_train, X_test = preprocess_GarageType(X_train, X_test)\n",
    "X_train, X_test = preprocess_GarageFinish(X_train, X_test)\n",
    "X_train, X_test = preprocess_GarageQual(X_train, X_test)\n",
    "X_train, X_test = preprocess_GarageCond(X_train, X_test)\n",
    "X_train, X_test = preprocess_PoolQC(X_train, X_test)\n",
    "X_train, X_test = preprocess_Fence(X_train, X_test)\n",
    "X_train, X_test = preprocess_MiscFeature(X_train, X_test)\n",
    "X_train, X_test = preprocess_Utilities(X_train, X_test)\n",
    "X_train, X_test = preprocess_Exterior1st(X_train, X_test)\n",
    "X_train, X_test = preprocess_Exterior2nd(X_train, X_test)\n",
    "X_train, X_test = preprocess_KitchenQual(X_train, X_test)\n",
    "X_train, X_test = preprocess_Functional(X_train, X_test)\n",
    "X_train, X_test = preprocess_SaleType(X_train, X_test)\n",
    "X_train, X_test = preprocess_GarageYrBlt(X_train, X_test)\n",
    "X_train, X_test = preprocess_MasVnrArea(X_train, X_test)\n",
    "\n",
    "X_train.drop(columns=['Street', 'Alley', 'Utilities'], inplace=True)\n",
    "X_test.drop(columns=['Street', 'Alley', 'Utilities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding\n",
    "Dummy Coding of categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_preprocessing import one_hot_encoding\n",
    "\n",
    "X_train.fillna(value=0, inplace=True)\n",
    "X_test.fillna(value=0, inplace=True)\n",
    "\n",
    "X_train, X_test = one_hot_encoding(X_train, X_test, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling\n",
    "Scaling to a range between 0 and 1 // Mean of 0 and Variance of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tobiasrummelsberger\\.virtualenvs\\house-price-prediction-_weolqlx\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\tobiasrummelsberger\\.virtualenvs\\house-price-prediction-_weolqlx\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "c:\\users\\tobiasrummelsberger\\.virtualenvs\\house-price-prediction-_weolqlx\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# SCALING\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train_scaled, columns=list(X_train), index=X_train.index)\n",
    "X_test = pd.DataFrame(data=X_test_scaled, columns=list(X_train), index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis\n",
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_preprocessing import principal_component_analysis\n",
    "\n",
    "#X_train, X_test = principal_component_analysis(X_train, X_test, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 109)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.8)\n",
    "\n",
    "pca.fit(X=X_train)\n",
    "X_train_decomposed = pca.transform(X_train)\n",
    "X_test_decomposed = pca.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train_decomposed, index=X_train.index)\n",
    "X_test = pd.DataFrame(data=X_test_decomposed, index=X_test.index)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 814549514.3800436\n",
      "MAPE: 0.579323108733706\n",
      "11.587101963192236\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from model import train_gridsearch_cv\n",
    "from model import negative_mean_absolute_percentage_error\n",
    "\n",
    "XGBoostRegressor = xgb.XGBRegressor()\n",
    "param_grid = {'eta':[0.2, 0.3, 0.5], \n",
    "              'max_deth':[3, 5], \n",
    "              'learning_rate':[0.01, 0.07], \n",
    "              'n_estimators':[1000,],\n",
    "              'booster':['gbtree',], \n",
    "              'min_child_weight':[0.5, 1.0, 2.0], \n",
    "              'subsample':[0.7, 1.0],\n",
    "              'random_state':[42,], \n",
    "              'tree_method': ['auto',], \n",
    "              'alpha': [2,],\n",
    "              'gamma': [1,],\n",
    "              'lambda':[1,], \n",
    "              'colsample_bytree': [1,]}\n",
    "model_xgb = train_gridsearch_cv(XGBoostRegressor, X_train, y_train, param_grid)\n",
    "print(-negative_mean_absolute_percentage_error(estimator=model_xgb, X=X_test, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    7.6s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1035467143.593118\n",
      "MAPE: 4.431028356670536\n",
      "4.431028356670536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from model import train_gridsearch_cv\n",
    "from model import negative_mean_absolute_percentage_error\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100],\n",
    "              'max_features': [None, 'auto'],\n",
    "              'min_samples_leaf': [2]}\n",
    "\n",
    "model_rf = train_gridsearch_cv(RandomForestRegressor(), X_train, y_train, param_grid)\n",
    "print(-negative_mean_absolute_percentage_error(estimator=model_rf, X=X_train, y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1232454621.2111886\n",
      "MAPE: 10.2008791553236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    0.3s finished\n",
      "c:\\users\\tobiasrummelsberger\\.virtualenvs\\house-price-prediction-_weolqlx\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from model import negative_mean_absolute_percentage_error\n",
    "from model import train_gridsearch_cv\n",
    "\n",
    "param_grid = {'alpha': [0.5, 1.0, 2.0],\n",
    "              'fit_intercept': ['True'],\n",
    "              'normalize': [True, False],\n",
    "              'positive': [True, False],\n",
    "              'max_iter': [5000,],\n",
    "              'tol': [0.0001, 0.00001]}\n",
    "model_el = train_gridsearch_cv(ElasticNet(), X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Sizes: 109 -> (21, 32, 10) -> 1\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from model import train_gridsearch_cv\n",
    "\n",
    "model_nn = MLPRegressor()\n",
    "\n",
    "inputs = int(len(list(X_train)))\n",
    "hidden_layers = (int(0.2*inputs), int(0.3*inputs), int(0.1*inputs))\n",
    "print(\"Layer Sizes:\", inputs, \"->\", hidden_layers, \"->\", 1)\n",
    "\n",
    "param_grid = {'hidden_layer_sizes': [hidden_layers],\n",
    "              'activation': ['relu'],\n",
    "              'alpha': [.001, 0.0001],\n",
    "              'solver': ['adam', 'lbfgs'],\n",
    "              'batch_size': [32, 128],\n",
    "              'learning_rate': ['invscaling',],\n",
    "              'learning_rate_init':[0.001, 0.01],\n",
    "              'max_iter': [7000,],\n",
    "              'early_stopping': [True,],\n",
    "              'n_iter_no_change': [15,],\n",
    "              'random_state':[42]}\n",
    "\n",
    "model_nn = train_gridsearch_cv(model_nn, X_train, y_train, param_grid)\n",
    "print(-negative_mean_absolute_percentage_error(estimator=model_nn, X=X_test, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "#from sklearn.joblib import dump, load\n",
    "\n",
    "model = XGBoostRegressor\n",
    "dump(model, PATH+MODEL_PATH+str(model)+'.joblib')\n",
    "\n",
    "model = model_nn\n",
    "dump(model, PATH+MODEL_PATH+str(model)+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Predicting results and combining regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgboost = model_xgb.predict(X_test)\n",
    "prediction_rf = model_rf.predict(X_test)\n",
    "prediction_el = model_el.predict(X_test)\n",
    "prediction_nn = model_nn.predict(X_test)\n",
    "\n",
    "prediction = pd.DataFrame(data=prediction_xgboost,\n",
    "                          columns=['XGBoost'],\n",
    "                          index=submission_index)\n",
    "#prediction['RandomForest'] = prediction_rf\n",
    "#prediction['ElasticNet'] = prediction_el\n",
    "#prediction['NeuralNet'] = prediction_nn\n",
    "prediction['SalePrice'] = prediction.mean(axis=1)\n",
    "prediction = prediction['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(data=prediction, columns=['SalePrice'], index=submission_index)\n",
    "prediction.to_csv(PATH + DATA_PATH + 'prediction_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house-price-prediction",
   "language": "python",
   "name": "house-price-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
